version: "3"

networks:
  #给监控用的，node_exporter什么的不暴露外网
  monitor:
    driver: bridge
    ipam:
      config:
        - subnet: 172.18.0.0/16


services:
#  建议用redis-stack,这两个端口冲突，不能部署在同一台机器
  myredis:
    build:
      context: redis/
      dockerfile: redis.dockerfile
    container_name: vergil-redis
    ports:
      - 26379:6379
#    deploy:
#      resources:
#        limits:
#          cpus: 4
#          memory: 8G
    healthcheck:
      test: [ "CMD", "redis-cli","ping" ]
#  myredisstack:
#    image: redis/redis-stack:7.2.0-v8
#    container_name: docker-redis
#    ports:
#      - 6379:6379
#    # 所有的配置需要在这里面加进去了，换配置文件很麻烦，得进镜像找去,现在发现这个还不生效
#    environment:
#      - REDIS_ARGS="--requirepass xyfs2023"
#    command:
#      - redis-server --requirepass xyfs2023
#    restart: always
#    healthcheck:
#      test: [ "CMD", "redis-cli","ping" ]

  mypostgres:
    image: postgres:16.3-alpine3.20
    container_name: vergil-postgres
    ports:
      - 25432:5432
    environment:
      POSTGRES_PASSWORD: xyfs2023
      POSTGRES_USER: postgres
      TZ: Asia/Shanghai
      PGTZ: Asia/Shanghai
    volumes:
      - /mnt/data/vergil/postgres:/var/lib/postgresql/data
    restart: always
#    deploy:
#      resources:
#        limits:
#          cpus: 4
#          memory: 8G
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5

  myrabbitmq:
    image: rabbitmq:3.13.2-management-alpine
    container_name: vergil-rabbitmq
    ports:
      - 25672:5672
      - 35672:15672
    environment:
      - RABBITMQ_DEFAULT_PASS=xyfs2023
      - RABBITMQ_DEFAULT_USER=vergil
    restart: always

  mymysql:
    build:
      context: mysql/
      dockerfile: mysql.dockerfile
    container_name: vergil-mysql
    environment:
      MYSQL_ROOT_PASSWORD: xyfs2023 #root管理员用户密码
      MYSQL_DATABASE: nacos_dev
      MYSQL_USER: nacosvergil
      MYSQL_PASSWORD: nacosxyfs2023
      LANG: C.UTF-8
    volumes:
      #mysql数据库挂载到host物理机目录
      - /mnt/data/vergil/mysql/db:/var/lib/mysql
      #容器的配置目录挂载到host物理机目录
      - /mnt/data/vergil/mysql/config:/etc/mysql/conf.d
    ports:
      - 23306:3306
    restart: always
#    deploy:
#      resources:
#        limits:
#          cpus: 4
#          memory: 8G
    healthcheck:
      test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost" ]
      interval: 5s
      timeout: 10s
      retries: 10

#  myelasticsearch:
#    image: elasticsearch:8.6.1
#    container_name: myelasticsearch
#    networks:
#      - ek-net
#    ports:
#      - 9200:9200
#      - 9300:9300
#    environment:
#      - "discovery.type=single-node"
#      - xpack.security.enabled=false  #没这玩意kibana就是跑不起来
#    volumes:
#      - /root/es/plugins:/usr/share/elasticsearch/plugins #插件文件挂载
#      - /root/es/data:/usr/share/elasticsearch/data #数据文件挂载
#  mykibana:
#    depends_on:
#      - myelasticsearch
#    image: kibana:8.6.1
#    container_name: mykibana
#    networks:
#      - ek-net
#    environment:
#      - ELASTICSEARCH_HOSTS=http://myelasticsearch:9200
#      - I18N_LOCALE="zh-CN"
#    ports:
#      - 5601:5601
#networks:
#  ek-net:
#    driver: bridge

  minio:
    image: quay.io/minio/minio:RELEASE.2024-05-07T06-41-25Z
    privileged: true
    container_name: myminio
    ports:
      - 29000:9000
      - 29090:9090
    command: minio server /data --console-address ":9090"
    environment:
      - MINIO_ROOT_USER=vergil
      - MINIO_ROOT_PASSWORD=xyfs2023
    volumes:
      - /mnt/data/vergil/minio:/data
    deploy:
      resources:
        limits:
          cpus: 4
          memory: 8G
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3

  mynacos:
    image: nacos/nacos-server:v2.3.2
    container_name: mynacos
    ports:
      - 28848:8848
      - 29848:9848
    volumes:
      - /mnt/data/vergil/nacos:/home/nacos/logs
    environment:
      - NACOS_AUTH_ENABLE=true
      - NACOS_AUTH_IDENTITY_KEY=123456
      - NACOS_AUTH_IDENTITY_VALUE=123456
      - NACOS_AUTH_TOKEN=MTIzNDU2Nzg5MTIzNDU2Nzg5MTIzNDU2Nzg5MTIzNDU2Nzg5
      - MODE=standalone
      - SPRING_DATASOURCE_PLATFORM=mysql
      # 必须给nacos配置公网IP，要不然注册的服务也拿不到公网IP
      - NACOS_SERVER_IP=223.72.5.68
      - MYSQL_SERVICE_HOST=223.72.5.68
      - MYSQL_SERVICE_DB_NAME=nacos_dev
      - MYSQL_SERVICE_PORT=23306
      - MYSQL_SERVICE_USER=nacosvergil
      - MYSQL_SERVICE_PASSWORD=nacosxyfs2023
      - MYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useSSL=false&allowPublicKeyRetrieval=true
    depends_on:
      mymysql:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          cpus: 4
          memory: 8G
#  sentinel:
#    build:
#      context: sentinel/
#      dockerfile: sentinel.dockerfile
#    image: mysentinel
#    container_name: mysentinel
#    ports:
#      - "8090:8090"
#      - "8719:8719"
#    restart: unless-stopped

#  myseata:
#    image: seataio/seata-server:2.0.0.jre17
#    ports:
#      - "7091:7091"
#      - "8091:8091"
#    environment:
#      - STORE_MODE=db
#      - SEATA_IP=113.141.90.115
#      - SEATA_PORT=8091
#      - TZ=Asia/Shanghai
#  etcd:
#    container_name: milvus-etcd
#    image: quay.io/coreos/etcd:v3.5.5
#    environment:
#      - ETCD_AUTO_COMPACTION_MODE=revision
#      - ETCD_AUTO_COMPACTION_RETENTION=1000
#      - ETCD_QUOTA_BACKEND_BYTES=4294967296
#      - ETCD_SNAPSHOT_COUNT=50000
#    volumes:
#      - /mnt/data/vergil/etcd:/etcd
#    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd

#  milvus:
#    build:
#      context: milvus/
#      dockerfile: milvus.dockerfile
##    image: milvusdb/milvus:v2.2.10
#    container_name: milvus-standalone
#    command: ["milvus", "run", "standalone"]
#    environment:
#      ETCD_ENDPOINTS: etcd:2379
#      MINIO_ADDRESS: minio:9000
#    volumes:
#      - /mnt/data/vergil/milvus:/var/lib/milvus
#    ports:
#      - "19530:19530"
#      - "9091:9091"
#    depends_on:
#      - "minio"
#      - "etcd"
#
#
#  attu:
#    container_name: attu
#    image: zilliz/attu:v2.2.3
#    environment:
#      MILVUS_URL: milvus-standalone:19530
#    ports:
#      - "3000:3000"
#    depends_on:
#      - "milvus"
#  palu:
#    container_name: mypalu
#    image: jammsen/palworld-dedicated-server:latest
#    restart: unless-stopped
#    ports:
#      - target: 8211 # 容器内游戏端口
#        published: 8212 # 宿主机映射端口
#        protocol: udp
#        mode: host
#      - target: 25575 # RCON 容器内
#        published: 25575 # RCON 宿主机映射端口
#        protocol: tcp
#        mode: host
#    volumes:
#      - /mnt/data/palu:/palworld # volume自己去指定
#    env_file:
#      - ./palword.env

#  rcon:
#    image: outdead/rcon:latest
#    entrypoint: ["/rcon", "-a", "113.141.90.115:25575", "-p", "xyfs2023"]
#    profiles: ["rcon"]
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    hostname: node_exporter
    ports:
      - 29100:9100
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    networks:
      - monitor

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: promethues
    restart: unless-stopped
    user: root
    ports:
      - 29091:9090
    volumes:
      - /mnt/data/monitor/config/prometheus.yml:/etc/prometheus/prometheus.yml
      - /mnt/data/monitor/prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention=7d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    # 监控docker用， https://docs.docker.com/config/daemon/prometheus
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - monitor

  grafana:
    image: grafana/grafana
    container_name: grafana
    hostname: grafana
    restart: unless-stopped
    ports:
      - "23000:3000"
    networks:
      - monitor
